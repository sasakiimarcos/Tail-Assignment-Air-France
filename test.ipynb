{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aad32cc-d6ea-42da-a0cd-677e08b5ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules de base\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Module relatif Ã  Gurobi\n",
    "from gurobipy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91a1a8-bec4-482f-ad58-3cf759910a3c",
   "metadata": {},
   "source": [
    "# Get and process files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73df1ca0-0549-40aa-b361-36f5d611a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple, Optional, Union\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) File locator (decoupled)\n",
    "# ----------------------------\n",
    "\n",
    "def _format_density(density: Union[int, float, str]) -> str:\n",
    "    \"\"\"\n",
    "    Convert density to the exact string used in folder/file names.\n",
    "    Examples:\n",
    "      1    -> \"1\"\n",
    "      0.9  -> \"0.9\"\n",
    "      0.95 -> \"0.95\"\n",
    "      \"4\"  -> \"4\"\n",
    "    \"\"\"\n",
    "    if isinstance(density, str):\n",
    "        s = density.strip()\n",
    "        # Normalize \"1.0\" -> \"1\" etc.\n",
    "        try:\n",
    "            f = float(s)\n",
    "            if f.is_integer():\n",
    "                return str(int(f))\n",
    "            return s.rstrip(\"0\").rstrip(\".\") if \".\" in s else s\n",
    "        except ValueError:\n",
    "            return s\n",
    "\n",
    "    if isinstance(density, (int, float)):\n",
    "        f = float(density)\n",
    "        if f.is_integer():\n",
    "            return str(int(f))\n",
    "        # keep minimal representation (0.90 -> 0.9)\n",
    "        s = repr(f)\n",
    "        return s.rstrip(\"0\").rstrip(\".\")\n",
    "    return str(density)\n",
    "\n",
    "\n",
    "def find_dat_file(\n",
    "    base_dir: Union[str, Path],\n",
    "    density: Union[int, float, str],\n",
    "    p: int,\n",
    "    h: int,\n",
    "    test: Optional[int] = None,\n",
    "    *,\n",
    "    top_folders: Tuple[str, str] = (\"Data\", \"Data with maintenance constraints\"),\n",
    "    folder_prefix: str = \"d=\",\n",
    "    file_prefix: str = \"DataCplex_\",\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Search for the .dat matching density/p/h/(optional)test under:\n",
    "      base_dir/Data/d=<density>/\n",
    "      base_dir/Data with maintenance constraints/d=<density>/\n",
    "    Returns the Path if uniquely found, otherwise raises an error.\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)\n",
    "    d_str = _format_density(density)\n",
    "\n",
    "    candidates: List[Path] = []\n",
    "\n",
    "    # Search both top folders (works even if one doesn't exist)\n",
    "    for top in top_folders:\n",
    "        d_folder = base_dir / top / f\"{folder_prefix}{d_str}\"\n",
    "        if not d_folder.exists():\n",
    "            continue\n",
    "\n",
    "        if test is None:\n",
    "            pattern = f\"{file_prefix}density={d_str}_p={p}_h={h}_test_*.dat\"\n",
    "        else:\n",
    "            pattern = f\"{file_prefix}density={d_str}_p={p}_h={h}_test_{test}.dat\"\n",
    "\n",
    "        candidates.extend(sorted(d_folder.glob(pattern)))\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No .dat file found for density={d_str}, p={p}, h={h}, test={test} under {base_dir}\"\n",
    "        )\n",
    "\n",
    "    # If test=None we might match multiple; require uniqueness to be safe\n",
    "    if len(candidates) > 1:\n",
    "        msg = \"\\n\".join(str(c) for c in candidates[:30])\n",
    "        more = \"\" if len(candidates) <= 30 else f\"\\n... and {len(candidates)-30} more\"\n",
    "        raise FileExistsError(\n",
    "            f\"Multiple matching .dat files found for density={d_str}, p={p}, h={h}, test={test}:\\n{msg}{more}\\n\"\n",
    "            f\"Pass test=<n> to select a unique file.\"\n",
    "        )\n",
    "\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Parser (decoupled)\n",
    "# ----------------------------\n",
    "\n",
    "_DECL_RE = re.compile(r\"(?ms)^\\s*(\\w+)\\s*=\\s*(.*?)\\s*;\\s*$\")\n",
    "\n",
    "def _parse_atom(token: str) -> Union[int, float, str]:\n",
    "    token = token.strip()\n",
    "    if token == \"\":\n",
    "        return token\n",
    "\n",
    "    # Try int then float\n",
    "    try:\n",
    "        if re.fullmatch(r\"[+-]?\\d+\", token):\n",
    "            return int(token)\n",
    "        if re.fullmatch(r\"[+-]?\\d*\\.\\d+(?:[eE][+-]?\\d+)?\", token) or re.fullmatch(r\"[+-]?\\d+(?:[eE][+-]?\\d+)\", token):\n",
    "            return float(token)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Otherwise string (e.g., airport codes A,B,C)\n",
    "    return token\n",
    "\n",
    "\n",
    "def _parse_set(value: str) -> List[Union[int, float, str]]:\n",
    "    # value like \"{A,B,C,}\" or \"{0,1,2,}\"\n",
    "    inner = value.strip()[1:-1].strip()\n",
    "    if inner == \"\":\n",
    "        return []\n",
    "    parts = [p.strip() for p in inner.split(\",\")]\n",
    "    parts = [p for p in parts if p != \"\"]\n",
    "    return [_parse_atom(p) for p in parts]\n",
    "\n",
    "\n",
    "def _parse_tuples_from_angle_brackets(value: str) -> List[Tuple[Union[int, float, str], ...]]:\n",
    "    # Extract all <...> blocks, split by commas inside\n",
    "    tuples: List[Tuple[Union[int, float, str], ...]] = []\n",
    "    for body in re.findall(r\"<([^<>]*)>\", value, flags=re.S):\n",
    "        fields = [f.strip() for f in body.split(\",\")]\n",
    "        fields = [f for f in fields if f != \"\"]\n",
    "        tuples.append(tuple(_parse_atom(f) for f in fields))\n",
    "    return tuples\n",
    "\n",
    "\n",
    "def _parse_matrix(value: str) -> List[List[Union[int, float]]]:\n",
    "    \"\"\"\n",
    "    Parses something like:\n",
    "      Cost =[\n",
    "        [6804.0,6870.0,...,]\n",
    "        [4536.0,4580.0,...,]\n",
    "      ];\n",
    "    Note: rows are NOT comma-separated in your file, so we scan bracket depth.\n",
    "    \"\"\"\n",
    "    s = value.strip()\n",
    "    if not (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "        raise ValueError(\"Matrix must start with '[' and end with ']'\")\n",
    "\n",
    "    content = s[1:-1].strip()\n",
    "\n",
    "    rows: List[str] = []\n",
    "    i = 0\n",
    "    n = len(content)\n",
    "    while i < n:\n",
    "        # Find next row '['\n",
    "        while i < n and content[i].isspace():\n",
    "            i += 1\n",
    "        if i >= n:\n",
    "            break\n",
    "        if content[i] != \"[\":\n",
    "            # skip unexpected chars\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # parse one row [...]\n",
    "        depth = 0\n",
    "        start = i\n",
    "        while i < n:\n",
    "            ch = content[i]\n",
    "            if ch == \"[\":\n",
    "                depth += 1\n",
    "            elif ch == \"]\":\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    end = i\n",
    "                    rows.append(content[start + 1 : end])  # inside [...]\n",
    "                    i += 1\n",
    "                    break\n",
    "            i += 1\n",
    "\n",
    "    matrix: List[List[Union[int, float]]] = []\n",
    "    for row in rows:\n",
    "        nums = [x.strip() for x in row.replace(\"\\n\", \" \").split(\",\")]\n",
    "        nums = [x for x in nums if x != \"\"]\n",
    "        parsed_row: List[Union[int, float]] = []\n",
    "        for x in nums:\n",
    "            atom = _parse_atom(x)\n",
    "            if isinstance(atom, str):\n",
    "                raise ValueError(f\"Non-numeric value in matrix: {atom!r}\")\n",
    "            parsed_row.append(atom)\n",
    "        matrix.append(parsed_row)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def parse_dat_file(dat_path: Union[str, Path]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parses an OPL/CPLEX-like .dat into a dict:\n",
    "      - Sets {...} -> Python list\n",
    "      - Scalars -> int/float/str\n",
    "      - Tuple lists <...> -> list[tuple]\n",
    "      - Matrices [...] with row brackets -> list[list[float/int]]\n",
    "    \"\"\"\n",
    "    dat_path = Path(dat_path)\n",
    "    text = dat_path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "    out: Dict[str, Any] = {}\n",
    "\n",
    "    # Split by semicolons safely by matching \"name = ... ;\" blocks (multiline)\n",
    "    for m in _DECL_RE.finditer(text):\n",
    "        name = m.group(1)\n",
    "        raw = m.group(2).strip()\n",
    "\n",
    "        if raw.startswith(\"{\") and raw.endswith(\"}\"):\n",
    "            # could be a set, or a tuple-set like Flight = { <...> <...> }\n",
    "            if \"<\" in raw and \">\" in raw:\n",
    "                out[name] = _parse_tuples_from_angle_brackets(raw)\n",
    "            else:\n",
    "                out[name] = _parse_set(raw)\n",
    "\n",
    "        elif raw.startswith(\"[\") and raw.endswith(\"]\"):\n",
    "            # could be matrix, or list of tuples inside brackets\n",
    "            if \"<\" in raw and \">\" in raw:\n",
    "                out[name] = _parse_tuples_from_angle_brackets(raw)\n",
    "            else:\n",
    "                out[name] = _parse_matrix(raw)\n",
    "\n",
    "        else:\n",
    "            # scalar\n",
    "            out[name] = _parse_atom(raw)\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c342d25c-1c43-429f-a561-749070c63741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['Airports', 'Nbflight', 'Aircrafts', 'Flight', 'Cost', 'Aircraft'])\n",
      "Nbflight: 793\n",
      "First Flight tuple: (1, 'A', 'B', 525.0, 715.0)\n",
      "Cost shape: 793 x 40\n",
      "First Aircraft tuple: (0, 'A')\n"
     ]
    }
   ],
   "source": [
    "base = Path.cwd()  # or Path(__file__).resolve().parent\n",
    "\n",
    "# Find file by params:\n",
    "dat_file = find_dat_file(base, density=1, p=40, h=7, test=9)\n",
    "\n",
    "data = parse_dat_file(dat_file)\n",
    "\n",
    "print(\"Keys:\", data.keys())\n",
    "print(\"Nbflight:\", data[\"Nbflight\"])\n",
    "print(\"First Flight tuple:\", data[\"Flight\"][0])\n",
    "print(\"Cost shape:\", len(data[\"Cost\"]), \"x\", len(data[\"Cost\"][0]) if data[\"Cost\"] else 0)\n",
    "print(\"First Aircraft tuple:\", data[\"Aircraft\"][0])\n",
    "\n",
    "Airports   = data[\"Airports\"]\n",
    "Nbflight   = data[\"Nbflight\"]\n",
    "Aircrafts  = data[\"Aircrafts\"]\n",
    "Flight     = data[\"Flight\"]\n",
    "Cost       = data[\"Cost\"]\n",
    "Aircraft   = data[\"Aircraft\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617ebcb-5a18-4f85-9dd3-ce0d4c72b61a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72307687-5475-4508-ab2b-79be1199ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "# xij where x is a binrary variable where i is the flight and j is the aircraft assignes\n",
    "\n",
    "X = {"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5093d-2f61-4a48-8915-fc94f4094968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
